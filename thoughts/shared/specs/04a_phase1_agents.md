# SRS 04 â€” Phase 1: Agents

| Field | Value |
|-------|-------|
| Version | 0.1.0 |
| Date | 2026-02-20 |
| Status | Draft |
| Spec ID | 04 of 09 |
| Requirement Prefix | REQ-P1- |

---

## Table of Contents

1. [Introduction](#1-introduction)
2. [Product Perspective](#2-product-perspective)
3. [A_retriever Requirements](#3-a_retriever-requirements)
4. [A_init Requirements](#4-a_init-requirements)
5. [A_merger Requirements](#5-a_merger-requirements)
6. [Algorithm 1 Orchestration Requirements](#6-algorithm-1-orchestration-requirements)
7. [Post-Merge Safety Requirements](#7-post-merge-safety-requirements)
8. [Non-Functional Requirements](#8-non-functional-requirements)
9. [Constraints](#9-constraints)
10. [Traceability Matrix](#10-traceability-matrix)
11. [Change Control](#11-change-control)

---

## 1. Introduction

### 1.1 Purpose

This SRS defines Phase 1 of the MLE-STAR pipeline: generating an initial solution from web-retrieved candidate models. It specifies three agents (A_retriever, A_init, A_merger), their orchestration according to Algorithm 1 from the paper, and the post-merge safety checks that produce a validated initial solution ready for Phase 2 refinement.

Intended audience: developers implementing the MLE-STAR system using the Claude Agent SDK for Python.

### 1.2 Scope

**Product name**: MLE-STAR (Machine Learning Engineering agent via Search and Targeted Refinement)

**What this spec covers**:
- A_retriever agent definition, prompt, tools, structured output, and output validation
- A_init agent definition, prompt, tools, and code block extraction from response
- A_merger agent definition, prompt, tools, and code block extraction from response
- Algorithm 1 orchestration: retrieve models, generate candidates, evaluate, sort, merge with break-on-first-failure
- Candidate evaluation and scoring
- Post-merge safety checks (A_data and A_leakage invocation)
- Phase1Result construction

**Out of scope**:
- Data model definitions (covered by Spec 01)
- Script execution and subprocess management (covered by Spec 02)
- Safety agent internals (covered by Spec 03; this spec only defines invocation points)
- Phase 2 refinement (covered by Specs 05-06)
- Phase 3 ensemble (covered by Spec 07)
- Orchestrator control flow (covered by Spec 09)

### 1.3 Definitions, Acronyms, and Abbreviations

| Term | Definition |
|------|-----------|
| SRS | Software Requirements Specification |
| MLE-STAR | ML Engineering agent with web Search and TArgeted code block Refinement |
| A_retriever | Retriever agent -- uses web search to find M effective models for the task |
| A_init | Initialization agent -- generates a candidate solution script for a given model |
| A_merger | Merger agent -- integrates a reference solution into a base solution via ensemble |
| T_task | Task description -- string describing the Kaggle competition |
| T_model^i | Model description -- name and example code for the i-th retrieved model |
| T_code^i | Example code -- concise code snippet demonstrating the i-th retrieved model |
| s_init^i | Initial candidate script -- solution generated by A_init for the i-th model |
| s_0 | Initial solution -- best merged solution output by Phase 1 |
| h(s) | Score function -- maps a solution script to a real-valued performance score |
| h_best | Best score -- the highest score achieved so far during merging |
| M | Number of candidate models retrieved via web search (default: 4) |
| pi | Permutation -- ordering of candidates by descending score |
| Algorithm 1 | "Generating an Initial Solution" algorithm from REF-01 Appendix B |

### 1.4 References

| ID | Title | Version | Source |
|----|-------|---------|--------|
| REF-01 | MLE-STAR paper | v3 | arXiv:2506.15692v3 |
| REF-02 | Claude Agent SDK reference | v0.1.39 | `claude-agent-sdk` PyPI |
| REF-03 | MLE-STAR architecture notes | -- | `thoughts/notes/mle_star_architecture.md` |
| REF-04 | MLE-STAR paper extraction | -- | `thoughts/notes/mle_star_paper.md` |
| REF-05 | Spec 01 -- Data Models and Interfaces | 0.1.0 | `thoughts/specs/01_data_models_and_interfaces.md` |
| REF-06 | Spec 02 -- Execution Harness | 0.1.0 | `thoughts/specs/02_execution_harness.md` |
| REF-07 | Spec 03 -- Safety Agents | 0.1.0 | `thoughts/specs/03_safety_modules.md` |

### 1.5 Document Overview

- Section 3: A_retriever requirements (agent definition, prompt, structured output, validation)
- Section 4: A_init requirements (agent definition, prompt, code extraction)
- Section 5: A_merger requirements (agent definition, prompt, code extraction)
- Section 6: Algorithm 1 orchestration (retrieve, evaluate candidates, sort, merge loop)
- Section 7: Post-merge safety checks (A_data and A_leakage invocation)
- Section 8: Non-functional requirements (parallelization, performance, observability)
- Section 9: Constraints (technology, algorithm fidelity)
- Section 10: Traceability matrix

---

## 2. Product Perspective

### 2.1 System Context

Phase 1 is the first computational phase of the MLE-STAR pipeline. It receives a task description and produces an initial solution `s_0` that becomes the input to Phase 2 (targeted code block refinement). Phase 1 implements Algorithm 1 from the paper.

```
Spec 01 (Data Models)
  |-- TaskDescription (REQ-DM-007)
  |-- PipelineConfig (REQ-DM-001) -- M parameter
  |-- SolutionScript (REQ-DM-009)
  |-- RetrievedModel (REQ-DM-014)
  |-- RetrieverOutput (REQ-DM-015)
  |-- Phase1Result (REQ-DM-022)
  |-- AgentType (REQ-DM-013)
  |-- AgentConfig (REQ-DM-036)
  |-- PromptRegistry (REQ-DM-032)
  |-- is_improvement_or_equal (REQ-DM-029)
  |
Spec 02 (Execution Harness)
  |-- evaluate_solution (REQ-EX-015)
  |-- evaluate_with_retry (REQ-EX-021)
  |-- evaluate_batch (REQ-EX-026)
  |-- rank_solutions (REQ-EX-027)
  |
Spec 03 (Safety Agents)
  |-- extract_code_block (REQ-SF-005)
  |-- check_and_fix_leakage (REQ-SF-020)
  |-- check_data_usage (REQ-SF-030)
  |-- make_debug_callback (REQ-SF-007)
  |
  v
Spec 04 (this) -- Phase 1: Initial Solution Generation
  |-- A_retriever: {T_model^i, T_code^i} = A_retriever(T_task)
  |-- A_init:     s_init^i = A_init(T_task, T_model^i, T_code^i)
  |-- A_merger:   s_candidate = A_merger(s_0, s_init^{pi(i)})
  |-- Output:     Phase1Result
  |
  v
Used by: Spec 05 (Phase 2 takes Phase1Result.initial_solution)
         Spec 09 (Orchestrator invokes Phase 1)
```

### 2.2 Product Functions Summary

1. Retrieve M candidate models via web search using A_retriever
2. Generate M candidate solution scripts using A_init (one per retrieved model)
3. Evaluate all M candidate solutions and rank by score
4. Sequentially merge lower-ranked candidates into the best candidate using A_merger, with break-on-first-failure
5. Run post-merge safety checks (A_data, A_leakage) on the final initial solution
6. Construct and return a Phase1Result

### 2.3 Operating Environment

- **Runtime**: Python 3.10+
- **SDK**: `claude-agent-sdk` v0.1.39+
- **Validation library**: Pydantic v2 (for RetrieverOutput structured output)
- **Execution**: Candidate evaluation delegates to Spec 02 harness
- **Web access**: A_retriever requires WebSearch and WebFetch SDK tools

### 2.4 Assumptions and Dependencies

| ID | Assumption | Impact if Invalid |
|----|-----------|-------------------|
| A-01 | Web search returns relevant ML models for the given task description | A_retriever may return irrelevant or outdated models |
| A-02 | LLM can generate executable Python scripts from model descriptions and example code | A_init may produce non-runnable solutions, requiring debugger intervention |
| A-03 | Simple ensemble merging improves or maintains score | Merging may degrade performance, in which case break-on-first-failure activates |
| A-04 | At least one of M candidates produces a non-None score after evaluation | Phase 1 fails if all candidates are non-executable |
| A-05 | The task description is sufficiently detailed for web search to find relevant models | Vague descriptions may yield poor retrieval results |

| ID | Dependency | Owner | Risk if Unavailable |
|----|-----------|-------|---------------------|
| D-01 | Spec 01 types (TaskDescription, PipelineConfig, SolutionScript, RetrievedModel, RetrieverOutput, Phase1Result, AgentType, AgentConfig, PromptRegistry, is_improvement_or_equal) | Spec 01 | Cannot construct inputs, outputs, or compare scores |
| D-02 | Spec 02 execution harness (evaluate_solution, evaluate_with_retry, evaluate_batch, rank_solutions) | Spec 02 | Cannot evaluate candidate scripts |
| D-03 | Spec 03 safety agents (extract_code_block, check_and_fix_leakage, check_data_usage, make_debug_callback) | Spec 03 | Cannot extract code from responses, cannot run safety checks |
| D-04 | `claude-agent-sdk` v0.1.39+ with WebSearch and WebFetch tools | Anthropic | A_retriever cannot search the web |
| D-05 | PromptRegistry with templates for retriever (Figure 9), init (Figure 10), merger (Figure 11) | Spec 01 | Cannot construct agent prompts |

---

## 3. A_retriever Requirements

### 3.1 Agent Definition

> **REQ-P1-001**: *A_retriever Agent Definition* -- The system shall define an `AgentDefinition`-compatible configuration for the retriever agent with the following properties:
>
> | Property | Value |
> |----------|-------|
> | `agent_type` | `AgentType.retriever` |
> | `description` | Agent that searches the web for effective ML models relevant to the competition task |
> | `prompt` | Rendered from the retriever template (Figure 9, REQ-DM-032) |
> | `tools` | `["WebSearch", "WebFetch"]` |
> | `output_schema` | `RetrieverOutput` (REQ-DM-015) |
> | `model` | `None` (inherit from orchestrator) |
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `AgentConfig(agent_type=AgentType.retriever).to_agent_definition()` shall produce a valid dictionary for `ClaudeAgentOptions.agents`.
> - Source: REF-01 Section 3.1, Figure 9

> **REQ-P1-002**: *A_retriever Prompt Template* -- The retriever agent prompt shall be constructed by rendering the Figure 9 template from the `PromptRegistry` (REQ-DM-032) with the following variables:
>
> | Variable | Type | Description |
> |----------|------|-------------|
> | `task_description` | `str` | Full task description text (`TaskDescription.description`) |
> | `M` | `int` | Number of models to retrieve (`PipelineConfig.num_retrieved_models`) |
>
> - The rendered prompt shall include all instructions from Figure 9: list M recent effective models, provide concise example codes, must provide example code (not just references to GitHub/papers), and the JSON schema for the response.
> - Priority: Must | Verify: Inspection | Release: MVP
> - Source: REF-01 Figure 9

> **REQ-P1-003**: *A_retriever Structured Output Configuration* -- The retriever agent shall use the Claude Agent SDK's `output_format` parameter set to `{"type": "json_schema", "schema": RetrieverOutput.model_json_schema()}` to ensure the response conforms to the `RetrieverOutput` schema (REQ-DM-015).
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: The agent response shall be parseable via `RetrieverOutput.model_validate_json(response)` without errors.
> - Source: REF-01 Figure 9, REF-02 Section 12 (Structured Outputs)

### 3.2 Output Validation

> **REQ-P1-004**: *A_retriever Output Parsing* -- The system shall define a function `parse_retriever_output(response: str) -> RetrieverOutput` that parses the agent's structured JSON response into a `RetrieverOutput` model (REQ-DM-015).
>
> - The function shall call `RetrieverOutput.model_validate_json(response)`.
> - If parsing fails (invalid JSON, schema validation error), the function shall raise `ValueError` with a descriptive message including the raw response (first 500 characters).
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: Given a valid JSON string conforming to `RetrieverOutput`, the function shall return a `RetrieverOutput` instance with a non-empty `models` list.

> **REQ-P1-005**: *A_retriever Model Count Validation* -- After parsing the retriever output, the system shall validate that `len(output.models) >= 1`. If `len(output.models) < M` (where M is `PipelineConfig.num_retrieved_models`), the system shall:
>
> 1. Log a warning indicating that fewer models were retrieved than requested (actual count vs. M).
> 2. Proceed with the available models (do not fail).
>
> - If `len(output.models) == 0`, the system shall raise `ValueError("A_retriever returned zero models")`.
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: Given a retriever output with 3 models when M=4, the system shall log a warning and proceed with 3 candidates.
> - Acceptance: Given a retriever output with 0 models, the system shall raise `ValueError`.
> - Source: REF-01 Algorithm 1 line 1 -- expects M models but must handle fewer

> **REQ-P1-006**: *A_retriever Model Field Validation* -- Each `RetrievedModel` (REQ-DM-014) in the parsed output shall be validated to ensure:
>
> 1. `model_name` is a non-empty string (length > 0 after stripping whitespace).
> 2. `example_code` is a non-empty string (length > 0 after stripping whitespace).
>
> - Models that fail validation shall be logged as warnings and excluded from the candidate list.
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: A `RetrievedModel` with `model_name=""` shall be excluded with a logged warning.
> - Source: REF-01 Figure 9 -- "You must provide an example code"

### 3.3 Invocation

> **REQ-P1-007**: *A_retriever Invocation Function* -- The system shall define an async function `retrieve_models(task: TaskDescription, config: PipelineConfig) -> list[RetrievedModel]` that:
>
> 1. Retrieves the retriever prompt template from the `PromptRegistry` (REQ-DM-032).
> 2. Renders the template with `task_description=task.description` and `M=config.num_retrieved_models`.
> 3. Invokes the retriever agent via the SDK with the rendered prompt, tools `["WebSearch", "WebFetch"]`, and `output_format` from `RetrieverOutput.model_json_schema()`.
> 4. Parses and validates the response (REQ-P1-004, REQ-P1-005, REQ-P1-006).
> 5. Returns the validated list of `RetrievedModel` instances.
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `retrieve_models(task, config)` shall return a list of `RetrievedModel` objects with length between 1 and M inclusive.

---

## 4. A_init Requirements

### 4.1 Agent Definition

> **REQ-P1-008**: *A_init Agent Definition* -- The system shall define an `AgentDefinition`-compatible configuration for the initialization agent with the following properties:
>
> | Property | Value |
> |----------|-------|
> | `agent_type` | `AgentType.init` |
> | `description` | Agent that generates an initial solution script using a specified ML model |
> | `prompt` | Rendered from the init template (Figure 10, REQ-DM-032) |
> | `tools` | `["Read"]` |
> | `output_schema` | `None` (free-form code block response) |
> | `model` | `None` (inherit from orchestrator) |
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `AgentConfig(agent_type=AgentType.init).to_agent_definition()` shall produce a valid dictionary for `ClaudeAgentOptions.agents`.
> - Source: REF-01 Section 3.1, Figure 10

> **REQ-P1-009**: *A_init Prompt Template* -- The initialization agent prompt shall be constructed by rendering the Figure 10 template from the `PromptRegistry` (REQ-DM-032) with the following variables:
>
> | Variable | Type | Description |
> |----------|------|-------------|
> | `task_description` | `str` | Full task description text (`TaskDescription.description`) |
> | `model_name` | `str` | Name of the retrieved model (`RetrievedModel.model_name`) |
> | `example_code` | `str` | Example code for the model (`RetrievedModel.example_code`) |
>
> - The rendered prompt shall include all instructions from Figure 10: use the specified model, simple solution without ensembling or hyperparameter optimization, propose an evaluation metric, data in `./input/`, use PyTorch not TensorFlow, use CUDA, subsample to 30,000, print "Final Validation Performance", single code block response, no `exit()`, no try/except masking.
> - Priority: Must | Verify: Inspection | Release: MVP
> - Source: REF-01 Figure 10

### 4.2 Output Contract

> **REQ-P1-010**: *A_init Output Contract* -- The initialization agent shall return a `SolutionScript` containing the generated Python code extracted from the agent's response.
>
> - The response shall be parsed using `extract_code_block()` (REQ-SF-005) to extract a single code block.
> - The returned `SolutionScript` shall have:
>   - `content`: the extracted code block
>   - `phase`: `SolutionPhase.init`
>   - `score`: `None` (not yet evaluated)
>   - `is_executable`: `True` (optimistic; will be verified by evaluation)
>   - `source_model`: the `RetrievedModel.model_name` used to generate this script
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: Given an agent response containing a fenced Python code block, the returned `SolutionScript.content` shall contain only the code within the fences, and `source_model` shall match the model name.
> - Source: REF-01 Algorithm 1 line 3 -- `s_init^i = A_init(T_task, T_model^i, T_code^i)`

> **REQ-P1-011**: *A_init Code Block Extraction* -- The system shall use `extract_code_block()` (REQ-SF-005) to extract the Python code from the A_init agent's text response. The extraction rules defined in REQ-SF-005 apply: prefer fenced code blocks, select the longest if multiple exist, fall back to the full response if no fences are present.
>
> - Priority: Must | Verify: Test | Release: MVP

### 4.3 Invocation

> **REQ-P1-012**: *A_init Invocation Function* -- The system shall define an async function `generate_candidate(task: TaskDescription, model: RetrievedModel, config: PipelineConfig) -> SolutionScript` that:
>
> 1. Retrieves the init prompt template from the `PromptRegistry` (REQ-DM-032).
> 2. Renders the template with `task_description=task.description`, `model_name=model.model_name`, and `example_code=model.example_code`.
> 3. Invokes the init agent via the SDK with the rendered prompt and tools `["Read"]`.
> 4. Extracts the code block from the response (REQ-P1-011).
> 5. Constructs and returns a `SolutionScript` (REQ-P1-010).
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `generate_candidate(task, model, config)` shall return a `SolutionScript` with `phase == SolutionPhase.init`, `source_model == model.model_name`, and non-empty `content`.

---

## 5. A_merger Requirements

### 5.1 Agent Definition

> **REQ-P1-013**: *A_merger Agent Definition* -- The system shall define an `AgentDefinition`-compatible configuration for the merger agent with the following properties:
>
> | Property | Value |
> |----------|-------|
> | `agent_type` | `AgentType.merger` |
> | `description` | Agent that integrates a reference solution into a base solution via ensemble |
> | `prompt` | Rendered from the merger template (Figure 11, REQ-DM-032) |
> | `tools` | `["Read"]` |
> | `output_schema` | `None` (free-form code block response) |
> | `model` | `None` (inherit from orchestrator) |
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `AgentConfig(agent_type=AgentType.merger).to_agent_definition()` shall produce a valid dictionary for `ClaudeAgentOptions.agents`.
> - Source: REF-01 Section 3.1, Figure 11

> **REQ-P1-014**: *A_merger Prompt Template* -- The merger agent prompt shall be constructed by rendering the Figure 11 template from the `PromptRegistry` (REQ-DM-032) with the following variables:
>
> | Variable | Type | Description |
> |----------|------|-------------|
> | `base_code` | `str` | Full source code of the current best solution (`s_0.content`) |
> | `reference_code` | `str` | Full source code of the next-ranked candidate solution (`s_init^{pi(i)}.content`) |
>
> - The rendered prompt shall include all instructions from Figure 11: integrate reference into base, code base should be the base solution, train additional model from reference, keep similar functionality together, ensemble the models, simple design, print "Final Validation Performance", single code block, data in `./input/`, subsample to 30,000, no `exit()`, no try/except masking.
> - Priority: Must | Verify: Inspection | Release: MVP
> - Source: REF-01 Figure 11

### 5.2 Output Contract

> **REQ-P1-015**: *A_merger Output Contract* -- The merger agent shall return a `SolutionScript` containing the merged Python code extracted from the agent's response.
>
> - The response shall be parsed using `extract_code_block()` (REQ-SF-005) to extract a single code block.
> - The returned `SolutionScript` shall have:
>   - `content`: the extracted code block
>   - `phase`: `SolutionPhase.merged`
>   - `score`: `None` (not yet evaluated)
>   - `is_executable`: `True` (optimistic; will be verified by evaluation)
>   - `source_model`: `None` (merged solutions have no single source model)
> - Priority: Must | Verify: Test | Release: MVP
> - Source: REF-01 Algorithm 1 line 9 -- `s_candidate = A_merger(s_0, s_init^{pi(i)})`

> **REQ-P1-016**: *A_merger Code Block Extraction* -- The system shall use `extract_code_block()` (REQ-SF-005) to extract the Python code from the A_merger agent's text response. The extraction rules defined in REQ-SF-005 apply.
>
> - Priority: Must | Verify: Test | Release: MVP

### 5.3 Invocation

> **REQ-P1-017**: *A_merger Invocation Function* -- The system shall define an async function `merge_solutions(base: SolutionScript, reference: SolutionScript, config: PipelineConfig) -> SolutionScript` that:
>
> 1. Retrieves the merger prompt template from the `PromptRegistry` (REQ-DM-032).
> 2. Renders the template with `base_code=base.content` and `reference_code=reference.content`.
> 3. Invokes the merger agent via the SDK with the rendered prompt and tools `["Read"]`.
> 4. Extracts the code block from the response (REQ-P1-016).
> 5. Constructs and returns a `SolutionScript` (REQ-P1-015).
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `merge_solutions(s_0, s_ref, config)` shall return a `SolutionScript` with `phase == SolutionPhase.merged` and non-empty `content`.
