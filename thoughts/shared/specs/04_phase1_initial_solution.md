# Software Requirements Specification: MLE-STAR Phase 1 -- Initial Solution Generation

| Field | Value |
|-------|-------|
| Version | 0.1.0 |
| Date | 2026-02-20 |
| Status | Draft |
| Spec ID | 04 of 09 |
| Requirement Prefix | REQ-P1- |

---

## Table of Contents

1. [Introduction](#1-introduction)
2. [Product Perspective](#2-product-perspective)
3. [A_retriever Requirements](#3-a_retriever-requirements)
4. [A_init Requirements](#4-a_init-requirements)
5. [A_merger Requirements](#5-a_merger-requirements)
6. [Algorithm 1 Orchestration Requirements](#6-algorithm-1-orchestration-requirements)
7. [Post-Merge Safety Requirements](#7-post-merge-safety-requirements)
8. [Non-Functional Requirements](#8-non-functional-requirements)
9. [Constraints](#9-constraints)
10. [Traceability Matrix](#10-traceability-matrix)
11. [Change Control](#11-change-control)

---

## 1. Introduction

### 1.1 Purpose

This SRS defines Phase 1 of the MLE-STAR pipeline: generating an initial solution from web-retrieved candidate models. It specifies three agents (A_retriever, A_init, A_merger), their orchestration according to Algorithm 1 from the paper, and the post-merge safety checks that produce a validated initial solution ready for Phase 2 refinement.

Intended audience: developers implementing the MLE-STAR system using the Claude Agent SDK for Python.

### 1.2 Scope

**Product name**: MLE-STAR (Machine Learning Engineering agent via Search and Targeted Refinement)

**What this spec covers**:
- A_retriever agent definition, prompt, tools, structured output, and output validation
- A_init agent definition, prompt, tools, and code block extraction from response
- A_merger agent definition, prompt, tools, and code block extraction from response
- Algorithm 1 orchestration: retrieve models, generate candidates, evaluate, sort, merge with break-on-first-failure
- Candidate evaluation and scoring
- Post-merge safety checks (A_data and A_leakage invocation)
- Phase1Result construction

**Out of scope**:
- Data model definitions (covered by Spec 01)
- Script execution and subprocess management (covered by Spec 02)
- Safety agent internals (covered by Spec 03; this spec only defines invocation points)
- Phase 2 refinement (covered by Specs 05-06)
- Phase 3 ensemble (covered by Spec 07)
- Orchestrator control flow (covered by Spec 09)

### 1.3 Definitions, Acronyms, and Abbreviations

| Term | Definition |
|------|-----------|
| SRS | Software Requirements Specification |
| MLE-STAR | ML Engineering agent with web Search and TArgeted code block Refinement |
| A_retriever | Retriever agent -- uses web search to find M effective models for the task |
| A_init | Initialization agent -- generates a candidate solution script for a given model |
| A_merger | Merger agent -- integrates a reference solution into a base solution via ensemble |
| T_task | Task description -- string describing the Kaggle competition |
| T_model^i | Model description -- name and example code for the i-th retrieved model |
| T_code^i | Example code -- concise code snippet demonstrating the i-th retrieved model |
| s_init^i | Initial candidate script -- solution generated by A_init for the i-th model |
| s_0 | Initial solution -- best merged solution output by Phase 1 |
| h(s) | Score function -- maps a solution script to a real-valued performance score |
| h_best | Best score -- the highest score achieved so far during merging |
| M | Number of candidate models retrieved via web search (default: 4) |
| pi | Permutation -- ordering of candidates by descending score |
| Algorithm 1 | "Generating an Initial Solution" algorithm from REF-01 Appendix B |

### 1.4 References

| ID | Title | Version | Source |
|----|-------|---------|--------|
| REF-01 | MLE-STAR paper | v3 | arXiv:2506.15692v3 |
| REF-02 | Claude Agent SDK reference | v0.1.39 | `claude-agent-sdk` PyPI |
| REF-03 | MLE-STAR architecture notes | -- | `thoughts/notes/mle_star_architecture.md` |
| REF-04 | MLE-STAR paper extraction | -- | `thoughts/notes/mle_star_paper.md` |
| REF-05 | Spec 01 -- Data Models and Interfaces | 0.1.0 | `thoughts/specs/01_data_models_and_interfaces.md` |
| REF-06 | Spec 02 -- Execution Harness | 0.1.0 | `thoughts/specs/02_execution_harness.md` |
| REF-07 | Spec 03 -- Safety Agents | 0.1.0 | `thoughts/specs/03_safety_modules.md` |

### 1.5 Document Overview

- Section 3: A_retriever requirements (agent definition, prompt, structured output, validation)
- Section 4: A_init requirements (agent definition, prompt, code extraction)
- Section 5: A_merger requirements (agent definition, prompt, code extraction)
- Section 6: Algorithm 1 orchestration (retrieve, evaluate candidates, sort, merge loop)
- Section 7: Post-merge safety checks (A_data and A_leakage invocation)
- Section 8: Non-functional requirements (parallelization, performance, observability)
- Section 9: Constraints (technology, algorithm fidelity)
- Section 10: Traceability matrix

---

## 2. Product Perspective

### 2.1 System Context

Phase 1 is the first computational phase of the MLE-STAR pipeline. It receives a task description and produces an initial solution `s_0` that becomes the input to Phase 2 (targeted code block refinement). Phase 1 implements Algorithm 1 from the paper.

```
Spec 01 (Data Models)
  |-- TaskDescription (REQ-DM-007)
  |-- PipelineConfig (REQ-DM-001) -- M parameter
  |-- SolutionScript (REQ-DM-009)
  |-- RetrievedModel (REQ-DM-014)
  |-- RetrieverOutput (REQ-DM-015)
  |-- Phase1Result (REQ-DM-022)
  |-- AgentType (REQ-DM-013)
  |-- AgentConfig (REQ-DM-036)
  |-- PromptRegistry (REQ-DM-032)
  |-- is_improvement_or_equal (REQ-DM-029)
  |
Spec 02 (Execution Harness)
  |-- evaluate_solution (REQ-EX-015)
  |-- evaluate_with_retry (REQ-EX-021)
  |-- evaluate_batch (REQ-EX-026)
  |-- rank_solutions (REQ-EX-027)
  |
Spec 03 (Safety Agents)
  |-- extract_code_block (REQ-SF-005)
  |-- check_and_fix_leakage (REQ-SF-020)
  |-- check_data_usage (REQ-SF-030)
  |-- make_debug_callback (REQ-SF-007)
  |
  v
Spec 04 (this) -- Phase 1: Initial Solution Generation
  |-- A_retriever: {T_model^i, T_code^i} = A_retriever(T_task)
  |-- A_init:     s_init^i = A_init(T_task, T_model^i, T_code^i)
  |-- A_merger:   s_candidate = A_merger(s_0, s_init^{pi(i)})
  |-- Output:     Phase1Result
  |
  v
Used by: Spec 05 (Phase 2 takes Phase1Result.initial_solution)
         Spec 09 (Orchestrator invokes Phase 1)
```

### 2.2 Product Functions Summary

1. Retrieve M candidate models via web search using A_retriever
2. Generate M candidate solution scripts using A_init (one per retrieved model)
3. Evaluate all M candidate solutions and rank by score
4. Sequentially merge lower-ranked candidates into the best candidate using A_merger, with break-on-first-failure
5. Run post-merge safety checks (A_data, A_leakage) on the final initial solution
6. Construct and return a Phase1Result

### 2.3 Operating Environment

- **Runtime**: Python 3.10+
- **SDK**: `claude-agent-sdk` v0.1.39+
- **Validation library**: Pydantic v2 (for RetrieverOutput structured output)
- **Execution**: Candidate evaluation delegates to Spec 02 harness
- **Web access**: A_retriever requires WebSearch and WebFetch SDK tools

### 2.4 Assumptions and Dependencies

| ID | Assumption | Impact if Invalid |
|----|-----------|-------------------|
| A-01 | Web search returns relevant ML models for the given task description | A_retriever may return irrelevant or outdated models |
| A-02 | LLM can generate executable Python scripts from model descriptions and example code | A_init may produce non-runnable solutions, requiring debugger intervention |
| A-03 | Simple ensemble merging improves or maintains score | Merging may degrade performance, in which case break-on-first-failure activates |
| A-04 | At least one of M candidates produces a non-None score after evaluation | Phase 1 fails if all candidates are non-executable |
| A-05 | The task description is sufficiently detailed for web search to find relevant models | Vague descriptions may yield poor retrieval results |

| ID | Dependency | Owner | Risk if Unavailable |
|----|-----------|-------|---------------------|
| D-01 | Spec 01 types (TaskDescription, PipelineConfig, SolutionScript, RetrievedModel, RetrieverOutput, Phase1Result, AgentType, AgentConfig, PromptRegistry, is_improvement_or_equal) | Spec 01 | Cannot construct inputs, outputs, or compare scores |
| D-02 | Spec 02 execution harness (evaluate_solution, evaluate_with_retry, evaluate_batch, rank_solutions) | Spec 02 | Cannot evaluate candidate scripts |
| D-03 | Spec 03 safety agents (extract_code_block, check_and_fix_leakage, check_data_usage, make_debug_callback) | Spec 03 | Cannot extract code from responses, cannot run safety checks |
| D-04 | `claude-agent-sdk` v0.1.39+ with WebSearch and WebFetch tools | Anthropic | A_retriever cannot search the web |
| D-05 | PromptRegistry with templates for retriever (Figure 9), init (Figure 10), merger (Figure 11) | Spec 01 | Cannot construct agent prompts |

---

## 3. A_retriever Requirements

### 3.1 Agent Definition

> **REQ-P1-001**: *A_retriever Agent Definition* -- The system shall define an `AgentDefinition`-compatible configuration for the retriever agent with the following properties:
>
> | Property | Value |
> |----------|-------|
> | `agent_type` | `AgentType.retriever` |
> | `description` | Agent that searches the web for effective ML models relevant to the competition task |
> | `prompt` | Rendered from the retriever template (Figure 9, REQ-DM-032) |
> | `tools` | `["WebSearch", "WebFetch"]` |
> | `output_schema` | `RetrieverOutput` (REQ-DM-015) |
> | `model` | `None` (inherit from orchestrator) |
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `AgentConfig(agent_type=AgentType.retriever).to_agent_definition()` shall produce a valid dictionary for `ClaudeAgentOptions.agents`.
> - Source: REF-01 Section 3.1, Figure 9

> **REQ-P1-002**: *A_retriever Prompt Template* -- The retriever agent prompt shall be constructed by rendering the Figure 9 template from the `PromptRegistry` (REQ-DM-032) with the following variables:
>
> | Variable | Type | Description |
> |----------|------|-------------|
> | `task_description` | `str` | Full task description text (`TaskDescription.description`) |
> | `M` | `int` | Number of models to retrieve (`PipelineConfig.num_retrieved_models`) |
>
> - The rendered prompt shall include all instructions from Figure 9: list M recent effective models, provide concise example codes, must provide example code (not just references to GitHub/papers), and the JSON schema for the response.
> - Priority: Must | Verify: Inspection | Release: MVP
> - Source: REF-01 Figure 9

> **REQ-P1-003**: *A_retriever Structured Output Configuration* -- The retriever agent shall use the Claude Agent SDK's `output_format` parameter set to `{"type": "json_schema", "schema": RetrieverOutput.model_json_schema()}` to ensure the response conforms to the `RetrieverOutput` schema (REQ-DM-015).
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: The agent response shall be parseable via `RetrieverOutput.model_validate_json(response)` without errors.
> - Source: REF-01 Figure 9, REF-02 Section 12 (Structured Outputs)

### 3.2 Output Validation

> **REQ-P1-004**: *A_retriever Output Parsing* -- The system shall define a function `parse_retriever_output(response: str) -> RetrieverOutput` that parses the agent's structured JSON response into a `RetrieverOutput` model (REQ-DM-015).
>
> - The function shall call `RetrieverOutput.model_validate_json(response)`.
> - If parsing fails (invalid JSON, schema validation error), the function shall raise `ValueError` with a descriptive message including the raw response (first 500 characters).
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: Given a valid JSON string conforming to `RetrieverOutput`, the function shall return a `RetrieverOutput` instance with a non-empty `models` list.

> **REQ-P1-005**: *A_retriever Model Count Validation* -- After parsing the retriever output, the system shall validate that `len(output.models) >= 1`. If `len(output.models) < M` (where M is `PipelineConfig.num_retrieved_models`), the system shall:
>
> 1. Log a warning indicating that fewer models were retrieved than requested (actual count vs. M).
> 2. Proceed with the available models (do not fail).
>
> - If `len(output.models) == 0`, the system shall raise `ValueError("A_retriever returned zero models")`.
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: Given a retriever output with 3 models when M=4, the system shall log a warning and proceed with 3 candidates.
> - Acceptance: Given a retriever output with 0 models, the system shall raise `ValueError`.
> - Source: REF-01 Algorithm 1 line 1 -- expects M models but must handle fewer

> **REQ-P1-006**: *A_retriever Model Field Validation* -- Each `RetrievedModel` (REQ-DM-014) in the parsed output shall be validated to ensure:
>
> 1. `model_name` is a non-empty string (length > 0 after stripping whitespace).
> 2. `example_code` is a non-empty string (length > 0 after stripping whitespace).
>
> - Models that fail validation shall be logged as warnings and excluded from the candidate list.
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: A `RetrievedModel` with `model_name=""` shall be excluded with a logged warning.
> - Source: REF-01 Figure 9 -- "You must provide an example code"

### 3.3 Invocation

> **REQ-P1-007**: *A_retriever Invocation Function* -- The system shall define an async function `retrieve_models(task: TaskDescription, config: PipelineConfig) -> list[RetrievedModel]` that:
>
> 1. Retrieves the retriever prompt template from the `PromptRegistry` (REQ-DM-032).
> 2. Renders the template with `task_description=task.description` and `M=config.num_retrieved_models`.
> 3. Invokes the retriever agent via the SDK with the rendered prompt, tools `["WebSearch", "WebFetch"]`, and `output_format` from `RetrieverOutput.model_json_schema()`.
> 4. Parses and validates the response (REQ-P1-004, REQ-P1-005, REQ-P1-006).
> 5. Returns the validated list of `RetrievedModel` instances.
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `retrieve_models(task, config)` shall return a list of `RetrievedModel` objects with length between 1 and M inclusive.

---

## 4. A_init Requirements

### 4.1 Agent Definition

> **REQ-P1-008**: *A_init Agent Definition* -- The system shall define an `AgentDefinition`-compatible configuration for the initialization agent with the following properties:
>
> | Property | Value |
> |----------|-------|
> | `agent_type` | `AgentType.init` |
> | `description` | Agent that generates an initial solution script using a specified ML model |
> | `prompt` | Rendered from the init template (Figure 10, REQ-DM-032) |
> | `tools` | `["Read"]` |
> | `output_schema` | `None` (free-form code block response) |
> | `model` | `None` (inherit from orchestrator) |
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `AgentConfig(agent_type=AgentType.init).to_agent_definition()` shall produce a valid dictionary for `ClaudeAgentOptions.agents`.
> - Source: REF-01 Section 3.1, Figure 10

> **REQ-P1-009**: *A_init Prompt Template* -- The initialization agent prompt shall be constructed by rendering the Figure 10 template from the `PromptRegistry` (REQ-DM-032) with the following variables:
>
> | Variable | Type | Description |
> |----------|------|-------------|
> | `task_description` | `str` | Full task description text (`TaskDescription.description`) |
> | `model_name` | `str` | Name of the retrieved model (`RetrievedModel.model_name`) |
> | `example_code` | `str` | Example code for the model (`RetrievedModel.example_code`) |
>
> - The rendered prompt shall include all instructions from Figure 10: use the specified model, simple solution without ensembling or hyperparameter optimization, propose an evaluation metric, data in `./input/`, use PyTorch not TensorFlow, use CUDA, subsample to 30,000, print "Final Validation Performance", single code block response, no `exit()`, no try/except masking.
> - Priority: Must | Verify: Inspection | Release: MVP
> - Source: REF-01 Figure 10

### 4.2 Output Contract

> **REQ-P1-010**: *A_init Output Contract* -- The initialization agent shall return a `SolutionScript` containing the generated Python code extracted from the agent's response.
>
> - The response shall be parsed using `extract_code_block()` (REQ-SF-005) to extract a single code block.
> - The returned `SolutionScript` shall have:
>   - `content`: the extracted code block
>   - `phase`: `SolutionPhase.init`
>   - `score`: `None` (not yet evaluated)
>   - `is_executable`: `True` (optimistic; will be verified by evaluation)
>   - `source_model`: the `RetrievedModel.model_name` used to generate this script
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: Given an agent response containing a fenced Python code block, the returned `SolutionScript.content` shall contain only the code within the fences, and `source_model` shall match the model name.
> - Source: REF-01 Algorithm 1 line 3 -- `s_init^i = A_init(T_task, T_model^i, T_code^i)`

> **REQ-P1-011**: *A_init Code Block Extraction* -- The system shall use `extract_code_block()` (REQ-SF-005) to extract the Python code from the A_init agent's text response. The extraction rules defined in REQ-SF-005 apply: prefer fenced code blocks, select the longest if multiple exist, fall back to the full response if no fences are present.
>
> - Priority: Must | Verify: Test | Release: MVP

### 4.3 Invocation

> **REQ-P1-012**: *A_init Invocation Function* -- The system shall define an async function `generate_candidate(task: TaskDescription, model: RetrievedModel, config: PipelineConfig) -> SolutionScript` that:
>
> 1. Retrieves the init prompt template from the `PromptRegistry` (REQ-DM-032).
> 2. Renders the template with `task_description=task.description`, `model_name=model.model_name`, and `example_code=model.example_code`.
> 3. Invokes the init agent via the SDK with the rendered prompt and tools `["Read"]`.
> 4. Extracts the code block from the response (REQ-P1-011).
> 5. Constructs and returns a `SolutionScript` (REQ-P1-010).
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `generate_candidate(task, model, config)` shall return a `SolutionScript` with `phase == SolutionPhase.init`, `source_model == model.model_name`, and non-empty `content`.

---

## 5. A_merger Requirements

### 5.1 Agent Definition

> **REQ-P1-013**: *A_merger Agent Definition* -- The system shall define an `AgentDefinition`-compatible configuration for the merger agent with the following properties:
>
> | Property | Value |
> |----------|-------|
> | `agent_type` | `AgentType.merger` |
> | `description` | Agent that integrates a reference solution into a base solution via ensemble |
> | `prompt` | Rendered from the merger template (Figure 11, REQ-DM-032) |
> | `tools` | `["Read"]` |
> | `output_schema` | `None` (free-form code block response) |
> | `model` | `None` (inherit from orchestrator) |
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `AgentConfig(agent_type=AgentType.merger).to_agent_definition()` shall produce a valid dictionary for `ClaudeAgentOptions.agents`.
> - Source: REF-01 Section 3.1, Figure 11

> **REQ-P1-014**: *A_merger Prompt Template* -- The merger agent prompt shall be constructed by rendering the Figure 11 template from the `PromptRegistry` (REQ-DM-032) with the following variables:
>
> | Variable | Type | Description |
> |----------|------|-------------|
> | `base_code` | `str` | Full source code of the current best solution (`s_0.content`) |
> | `reference_code` | `str` | Full source code of the next-ranked candidate solution (`s_init^{pi(i)}.content`) |
>
> - The rendered prompt shall include all instructions from Figure 11: integrate reference into base, code base should be the base solution, train additional model from reference, keep similar functionality together, ensemble the models, simple design, print "Final Validation Performance", single code block, data in `./input/`, subsample to 30,000, no `exit()`, no try/except masking.
> - Priority: Must | Verify: Inspection | Release: MVP
> - Source: REF-01 Figure 11

### 5.2 Output Contract

> **REQ-P1-015**: *A_merger Output Contract* -- The merger agent shall return a `SolutionScript` containing the merged Python code extracted from the agent's response.
>
> - The response shall be parsed using `extract_code_block()` (REQ-SF-005) to extract a single code block.
> - The returned `SolutionScript` shall have:
>   - `content`: the extracted code block
>   - `phase`: `SolutionPhase.merged`
>   - `score`: `None` (not yet evaluated)
>   - `is_executable`: `True` (optimistic; will be verified by evaluation)
>   - `source_model`: `None` (merged solutions have no single source model)
> - Priority: Must | Verify: Test | Release: MVP
> - Source: REF-01 Algorithm 1 line 9 -- `s_candidate = A_merger(s_0, s_init^{pi(i)})`

> **REQ-P1-016**: *A_merger Code Block Extraction* -- The system shall use `extract_code_block()` (REQ-SF-005) to extract the Python code from the A_merger agent's text response. The extraction rules defined in REQ-SF-005 apply.
>
> - Priority: Must | Verify: Test | Release: MVP

### 5.3 Invocation

> **REQ-P1-017**: *A_merger Invocation Function* -- The system shall define an async function `merge_solutions(base: SolutionScript, reference: SolutionScript, config: PipelineConfig) -> SolutionScript` that:
>
> 1. Retrieves the merger prompt template from the `PromptRegistry` (REQ-DM-032).
> 2. Renders the template with `base_code=base.content` and `reference_code=reference.content`.
> 3. Invokes the merger agent via the SDK with the rendered prompt and tools `["Read"]`.
> 4. Extracts the code block from the response (REQ-P1-016).
> 5. Constructs and returns a `SolutionScript` (REQ-P1-015).
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `merge_solutions(s_0, s_ref, config)` shall return a `SolutionScript` with `phase == SolutionPhase.merged` and non-empty `content`.

---

## 6. Algorithm 1 Orchestration Requirements

### 6.1 End-to-End Phase 1 Function

> **REQ-P1-018**: *Phase 1 Entry Point* -- The system shall define an async function `run_phase1(task: TaskDescription, config: PipelineConfig) -> Phase1Result` that implements Algorithm 1 from REF-01 Appendix B. This function orchestrates the full Phase 1 pipeline: retrieval, candidate generation, evaluation, sorting, and merging.
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `run_phase1(task, config)` shall return a `Phase1Result` (REQ-DM-022) with a non-None `initial_solution` and `initial_score`.
> - Source: REF-01 Algorithm 1

### 6.2 Step 1: Model Retrieval

> **REQ-P1-019**: *Algorithm 1 Step 1 -- Model Retrieval* -- The `run_phase1` function shall begin by invoking `retrieve_models(task, config)` (REQ-P1-007) to obtain a list of M retrieved models.
>
> - This corresponds to Algorithm 1 line 1: `{T_model^i, T_code^i}_{i=1}^M = A_retriever(T_task)`.
> - The retrieved models shall be stored for inclusion in the `Phase1Result`.
> - Priority: Must | Verify: Test | Release: MVP
> - Source: REF-01 Algorithm 1 line 1

### 6.3 Steps 2-5: Candidate Generation and Evaluation

> **REQ-P1-020**: *Algorithm 1 Steps 2-5 -- Candidate Generation* -- For each retrieved model (i = 1 to M), the `run_phase1` function shall:
>
> 1. Invoke `generate_candidate(task, model_i, config)` (REQ-P1-012) to produce `s_init^i`.
> 2. Run the leakage checker on the candidate: `s_init^i = check_and_fix_leakage(s_init^i)` (REQ-SF-022).
> 3. Evaluate the candidate using `evaluate_with_retry(s_init^i, task, config, debug_callback)` (REQ-EX-021) to obtain `(s_init^i, result_i)`.
> 4. Record `s_init^i` and the resulting score `result_i.score`.
>
> - This corresponds to Algorithm 1 lines 2-5.
> - Priority: Must | Verify: Test | Release: MVP
> - Source: REF-01 Algorithm 1 lines 2-5

> **REQ-P1-021**: *Candidate Evaluation Failure Handling* -- If a candidate `s_init^i` fails to execute (i.e., `result_i.is_error == True` after all debug retries are exhausted):
>
> 1. Log a warning indicating the candidate failed: model name, error summary (first line of traceback).
> 2. Record the candidate's score as `None`.
> 3. Continue to the next candidate. Do not abort Phase 1.
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: Given M=4 candidates where 2 fail to execute, the system shall proceed with the 2 successful candidates for sorting and merging.
> - Source: REF-01 Algorithm 1 -- implicit; the algorithm evaluates all candidates

> **REQ-P1-022**: *All Candidates Failed* -- If all M candidates fail to execute (all scores are `None`), the `run_phase1` function shall raise a `RuntimeError("Phase 1 failed: all {M} candidates produced execution errors")`.
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: Given M=4 candidates where all 4 fail, the function shall raise `RuntimeError`.

### 6.4 Step 6: Sort Candidates by Score

> **REQ-P1-023**: *Algorithm 1 Step 6 -- Sort by Score* -- After evaluating all candidates, the `run_phase1` function shall sort the successful candidates (those with non-None scores) by score in the best-first order using `rank_solutions()` (REQ-EX-027) with the task's `metric_direction`.
>
> - This produces the permutation pi where pi(1) is the best-scoring candidate.
> - Candidates with `None` scores shall be placed at the end and excluded from the merge loop.
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: For `direction="maximize"` with candidate scores `[0.7, 0.9, 0.8, None]`, the sorted order shall be `[0.9, 0.8, 0.7]` (excluding None).
> - Source: REF-01 Algorithm 1 line 6 -- `s_0 <- s_init^{pi(1)}`

> **REQ-P1-024**: *Algorithm 1 Step 6-7 -- Initialize Best Solution* -- The `run_phase1` function shall set the initial best solution and score:
>
> - `s_0 = s_init^{pi(1)}` (the best-scoring candidate)
> - `h_best = h(s_0)` (the score of the best candidate)
>
> - This corresponds to Algorithm 1 lines 6-7.
> - Priority: Must | Verify: Test | Release: MVP
> - Source: REF-01 Algorithm 1 lines 6-7

### 6.5 Steps 8-17: Merge Loop

> **REQ-P1-025**: *Algorithm 1 Steps 8-17 -- Merge Loop* -- The `run_phase1` function shall iterate over the remaining sorted candidates (i = 2 to M, sorted by score descending) and for each:
>
> 1. Invoke `merge_solutions(s_0, s_init^{pi(i)}, config)` (REQ-P1-017) to produce `s_candidate`.
> 2. Run the leakage checker: `s_candidate = check_and_fix_leakage(s_candidate)` (REQ-SF-022).
> 3. Evaluate `s_candidate` using `evaluate_with_retry(s_candidate, task, config, debug_callback)` (REQ-EX-021).
> 4. Compare the score using `is_improvement_or_equal(h(s_candidate), h_best, direction)` (REQ-DM-029).
> 5. If the merged candidate improves or equals the best score:
>    - Update `s_0 = s_candidate` and `h_best = h(s_candidate)`.
>    - Continue to the next candidate.
> 6. If the merged candidate does not improve:
>    - **Break** out of the merge loop (do not attempt further merges).
>
> - This implements Algorithm 1 lines 8-17 with the break-on-first-failure semantics of line 15.
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: Given sorted candidates with scores `[0.9, 0.85, 0.8]` where merging s_0 with the second produces score 0.91 and merging with the third produces score 0.89, the function shall stop after the third merge (since 0.89 < 0.91) and return `s_0` with `h_best = 0.91`.
> - Source: REF-01 Algorithm 1 lines 8-17

> **REQ-P1-026**: *Merge Loop Score Comparison Semantics* -- The merge loop score comparison shall use `is_improvement_or_equal()` (REQ-DM-029), not strict improvement (`is_improvement`, REQ-DM-028). This means a merge that achieves the same score as the current best is accepted and merging continues.
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: If `h_best = 0.85` and the merged candidate scores `0.85`, the merge shall be accepted (s_0 updated) and the loop shall continue.
> - Source: REF-01 Algorithm 1 line 11 -- `if h(s_candidate) >= h_best then`

> **REQ-P1-027**: *Merge Loop Break-on-First-Failure* -- The merge loop shall terminate immediately upon the first merge that fails to improve or equal the best score. No further merge attempts shall be made after this point.
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: Given 3 remaining candidates to merge, if the first merge succeeds but the second fails, only 2 merges shall be attempted (not 3).
> - Source: REF-01 Algorithm 1 lines 14-16 -- `else: break`

> **REQ-P1-028**: *Merge Candidate Execution Failure* -- If a merged candidate `s_candidate` fails to execute (after debug retries), the system shall treat this as a failed merge (score did not improve) and break out of the merge loop, consistent with break-on-first-failure semantics.
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: If the merge produces a script that cannot execute even after debugging, the merge loop shall terminate and `s_0` shall remain unchanged.

### 6.6 Single Candidate Case

> **REQ-P1-029**: *Single Candidate -- No Merge Required* -- If only one candidate has a non-None score after evaluation (either because M=1 or because all other candidates failed), the merge loop shall be skipped entirely. The single successful candidate becomes `s_0` directly.
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: Given M=4 where only one candidate succeeds, `s_0` shall be that candidate's solution with no merge attempts.

---

## 7. Post-Merge Safety Requirements

### 7.1 A_data Invocation

> **REQ-P1-030**: *Post-Merge Data Check* -- After the merge loop completes and `s_0` is finalized, the `run_phase1` function shall invoke `check_data_usage(s_0, task)` (REQ-SF-030) to ensure all provided data sources are utilized.
>
> - The returned solution shall replace `s_0`: `s_0 = check_data_usage(s_0, task)`.
> - If the data agent modifies the solution, the modified solution shall be re-evaluated using `evaluate_with_retry()` to obtain an updated score. If the modified solution fails to execute after debug retries, the system shall fall back to the pre-A_data version of `s_0` (REQ-SF-008 fallback semantics).
> - This corresponds to the paper's `s_0 <- A_data(s_0, T_task)` step that occurs after Algorithm 1.
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: After merging, `check_data_usage` shall be called exactly once with the merged `s_0` and the task description.
> - Source: REF-01 Section 3.4, REQ-SF-030 -- "A_data runs once after initial solution generation (Phase 1 only)"

### 7.2 A_leakage Invocation

> **REQ-P1-031**: *Post-Data-Check Leakage Check* -- After the A_data check (REQ-P1-030), the `run_phase1` function shall invoke `check_and_fix_leakage(s_0)` (REQ-SF-020) on the final solution.
>
> - The returned solution shall replace `s_0`: `s_0 = check_and_fix_leakage(s_0)`.
> - If the leakage agent modifies the solution, the modified solution shall be re-evaluated using `evaluate_with_retry()` to obtain an updated score.
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: After the A_data check, `check_and_fix_leakage` shall be called on the resulting solution.
> - Source: REF-01 Section 3.4, REQ-SF-022 -- "A_leakage runs before every evaluation"

### 7.3 Phase1Result Construction

> **REQ-P1-032**: *Phase1Result Construction* -- After all post-merge safety checks complete, the `run_phase1` function shall construct a `Phase1Result` (REQ-DM-022) with:
>
> | Field | Value |
> |-------|-------|
> | `retrieved_models` | The list of `RetrievedModel` instances returned by A_retriever |
> | `candidate_solutions` | The list of `SolutionScript` instances produced by A_init (all M, including failed ones) |
> | `candidate_scores` | The list of scores (as `float | None`) for each candidate, in the same order as `candidate_solutions` |
> | `initial_solution` | The final `s_0` after merging and safety checks |
> | `initial_score` | The score of the final `s_0` (`h_best` after all post-merge steps) |
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: The returned `Phase1Result` shall have `len(candidate_solutions) == len(candidate_scores) == len(retrieved_models)` (or fewer if retrieval returned fewer than M).
> - Source: REQ-DM-022

> **REQ-P1-033**: *Phase1Result Score Consistency* -- The `Phase1Result.initial_score` shall reflect the score of `Phase1Result.initial_solution` after all post-merge safety checks. If post-merge safety checks altered the solution and re-evaluation produced a different score, `initial_score` shall reflect the final re-evaluated score.
>
> - Priority: Must | Verify: Test | Release: MVP
> - Acceptance: `Phase1Result.initial_score` shall equal the score obtained from evaluating `Phase1Result.initial_solution`.

---

## 8. Non-Functional Requirements

### 8.1 Parallelization

> **REQ-P1-034**: *Candidate Generation Independence* -- The M candidate generations (A_init invocations in Algorithm 1 lines 2-5) are independent of each other. The system should document this independence to enable future parallel execution.
>
> - The current implementation shall execute candidate generations sequentially (consistent with REQ-EX-026 sequential batch evaluation).
> - A future optimization may execute them concurrently, as no candidate depends on another's output.
> - Priority: Should | Verify: Inspection | Release: MVP
> - Source: REF-01 Algorithm 1 lines 2-5 -- each iteration is independent

> **REQ-P1-035**: *Candidate Evaluation Independence* -- The M candidate evaluations (Algorithm 1 lines 4) are independent of each other and may be executed concurrently in a future optimization.
>
> - The current implementation shall use `evaluate_batch()` (REQ-EX-026) which evaluates sequentially.
> - Priority: Should | Verify: Inspection | Release: MVP

> **REQ-P1-036**: *Merge Loop Sequential Requirement* -- The merge loop (Algorithm 1 lines 8-17) is inherently sequential: each merge depends on the current `s_0` which may have been updated by the previous merge. The merge loop shall not be parallelized.
>
> - Priority: Must | Verify: Inspection | Release: MVP
> - Source: REF-01 Algorithm 1 lines 8-17 -- `s_0` is updated in each iteration

### 8.2 Performance

> **REQ-P1-037**: *Phase 1 Overhead Budget* -- The Phase 1 orchestration overhead (prompt rendering, output parsing, score comparison, Phase1Result construction) excluding agent LLM calls and script execution time shall not exceed 5 seconds total.
>
> - Priority: Should | Verify: Test | Release: MVP

### 8.3 Observability

> **REQ-P1-038**: *Phase 1 Logging* -- The Phase 1 orchestration shall log the following events using Python's `logging` module at the specified levels:
>
> | Event | Level | Content |
> |-------|-------|---------|
> | Phase 1 start | `INFO` | Competition ID, M value |
> | Retrieval complete | `INFO` | Number of models retrieved, model names |
> | Candidate generation start | `INFO` | Model index (i/M), model name |
> | Candidate generation complete | `INFO` | Model name, code length |
> | Candidate evaluation result | `INFO` | Model name, score (or "failed"), duration |
> | Candidate skipped (execution failure) | `WARNING` | Model name, error summary |
> | All candidates failed | `ERROR` | M value, all model names |
> | Candidates sorted | `INFO` | Sorted order (model names and scores) |
> | Merge attempt start | `INFO` | Merge index, base score, reference model name |
> | Merge attempt result | `INFO` | Merged score, accepted or rejected |
> | Merge loop break | `INFO` | Reason (score did not improve), merge index |
> | Post-merge A_data start | `INFO` | Solution content length |
> | Post-merge A_data result | `INFO` | Whether solution was modified |
> | Post-merge A_leakage start | `INFO` | Solution content length |
> | Post-merge A_leakage result | `INFO` | Whether leakage was detected and corrected |
> | Phase 1 complete | `INFO` | Final score, total duration, number of merges performed |
>
> - Priority: Must | Verify: Inspection | Release: MVP

---

## 9. Constraints

### 9.1 Technology Constraints

> **REQ-P1-039**: *SDK Agent Invocation* -- All three Phase 1 agents (A_retriever, A_init, A_merger) shall be invoked via the Claude Agent SDK agent mechanism. They shall not use direct API calls, raw HTTP requests, or any non-SDK LLM invocation method.
>
> - Priority: Must | Verify: Inspection | Release: MVP
> - Source: REF-02 -- all agent interactions through the SDK

> **REQ-P1-040**: *Single Module Organization* -- All Phase 1 functions defined in this spec shall reside in a single Python module (e.g., `mle_star/phase1.py`).
>
> - Priority: Should | Verify: Inspection | Release: MVP

### 9.2 Algorithm Fidelity Constraints

> **REQ-P1-041**: *Algorithm 1 Fidelity* -- The Phase 1 implementation shall faithfully reproduce Algorithm 1 from REF-01 Appendix B. Specifically:
>
> 1. Retrieval shall occur exactly once (line 1).
> 2. All M candidates shall be generated and evaluated (lines 2-5).
> 3. Candidates shall be sorted by score, best first (line 6).
> 4. The best candidate shall be selected as the initial `s_0` (lines 6-7).
> 5. Merging shall iterate over remaining sorted candidates in descending score order (lines 8-17).
> 6. The merge loop shall use `>=` comparison (line 11), not strict `>`.
> 7. The merge loop shall break on first failure (line 15).
>
> - Deviations from Algorithm 1 are permitted only for error handling (e.g., skipping failed candidates, debugging), which the paper does not address explicitly.
> - Priority: Must | Verify: Inspection | Release: MVP
> - Source: REF-01 Appendix B, Algorithm 1

> **REQ-P1-042**: *Leakage Check Integration Points* -- Within Phase 1, the leakage checker `check_and_fix_leakage()` (REQ-SF-022) shall be invoked:
>
> 1. On each candidate `s_init^i` before evaluation (REQ-P1-020 step 2).
> 2. On each merged candidate `s_candidate` before evaluation (REQ-P1-025 step 2).
> 3. On the final `s_0` during post-merge safety checks (REQ-P1-031).
>
> - This ensures every solution that enters evaluation has been checked for data leakage.
> - Priority: Must | Verify: Inspection | Release: MVP
> - Source: REF-01 Section 3.4, REQ-SF-022

### 9.3 Prompt Fidelity Constraints

> **REQ-P1-043**: *A_retriever Prompt Fidelity* -- The A_retriever prompt (REQ-P1-002) shall preserve the semantic intent of Figure 9 from the paper. The prompt shall include:
>
> 1. The competition task description (verbatim from `TaskDescription.description`).
> 2. The instruction to list M recent effective models.
> 3. The requirement that example code be concise and simple.
> 4. The requirement that example code must be provided (no GitHub/paper references only).
> 5. The JSON schema for the response format.
>
> - Priority: Must | Verify: Inspection | Release: MVP
> - Source: REF-01 Figure 9

> **REQ-P1-044**: *A_init Prompt Fidelity* -- The A_init prompt (REQ-P1-009) shall preserve the semantic intent of Figure 10 from the paper. The prompt shall include:
>
> 1. The Kaggle grandmaster persona introduction.
> 2. The task description.
> 3. The model name and example code.
> 4. Instructions to implement using the specified model.
> 5. Instruction for simple solution (no ensembling, no hyperparameter optimization).
> 6. The `./input/` data directory instruction.
> 7. The PyTorch-over-TensorFlow preference.
> 8. The 30,000 subsample limit instruction.
> 9. The "Final Validation Performance" output requirement.
> 10. The single code block response format.
> 11. The no-`exit()` constraint.
> 12. The no-try/except constraint.
>
> - Priority: Must | Verify: Inspection | Release: MVP
> - Source: REF-01 Figure 10

> **REQ-P1-045**: *A_merger Prompt Fidelity* -- The A_merger prompt (REQ-P1-014) shall preserve the semantic intent of Figure 11 from the paper. The prompt shall include:
>
> 1. The Kaggle grandmaster persona introduction.
> 2. The base solution code.
> 3. The reference solution code.
> 4. Instruction to integrate reference into base.
> 5. Instruction that code base should be the base solution.
> 6. Instruction to train additional model from reference.
> 7. Instruction to keep similar functionality together.
> 8. Instruction to ensemble the models.
> 9. Instruction for simple design.
> 10. The "Final Validation Performance" output requirement.
> 11. The single code block response format.
> 12. The `./input/` data directory instruction.
> 13. The 30,000 subsample limit instruction.
> 14. The no-`exit()` constraint.
> 15. The no-try/except constraint.
>
> - Priority: Must | Verify: Inspection | Release: MVP
> - Source: REF-01 Figure 11

---

## 10. Traceability Matrix

### 10.1 Requirements to Paper Sections

| Req ID | Paper Section | Paper Element | SDK Construct |
|--------|--------------|---------------|---------------|
| REQ-P1-001 | Section 3.1 | A_retriever agent | `AgentDefinition` |
| REQ-P1-002 | Figure 9 | Retriever prompt template | `prompt` parameter |
| REQ-P1-003 | Figure 9 | Retriever structured output | `output_format` |
| REQ-P1-004 | Figure 9 | Retriever output parsing | `RetrieverOutput.model_validate_json()` |
| REQ-P1-005 | Algorithm 1 line 1 | M models expected | -- |
| REQ-P1-006 | Figure 9 | Model field validation | -- |
| REQ-P1-007 | Algorithm 1 line 1 | `A_retriever(T_task)` invocation | SDK agent call |
| REQ-P1-008 | Section 3.1 | A_init agent | `AgentDefinition` |
| REQ-P1-009 | Figure 10 | Init prompt template | `prompt` parameter |
| REQ-P1-010 | Algorithm 1 line 3 | `s_init^i = A_init(...)` output | -- |
| REQ-P1-011 | Figure 10 | Code block extraction | -- |
| REQ-P1-012 | Algorithm 1 line 3 | `A_init(T_task, T_model^i, T_code^i)` invocation | SDK agent call |
| REQ-P1-013 | Section 3.1 | A_merger agent | `AgentDefinition` |
| REQ-P1-014 | Figure 11 | Merger prompt template | `prompt` parameter |
| REQ-P1-015 | Algorithm 1 line 9 | `s_candidate = A_merger(...)` output | -- |
| REQ-P1-016 | Figure 11 | Code block extraction | -- |
| REQ-P1-017 | Algorithm 1 line 9 | `A_merger(s_0, s_init^{pi(i)})` invocation | SDK agent call |
| REQ-P1-018 | Algorithm 1 | Full Phase 1 entry point | -- |
| REQ-P1-019 | Algorithm 1 line 1 | Model retrieval step | -- |
| REQ-P1-020 | Algorithm 1 lines 2-5 | Candidate generation + evaluation loop | -- |
| REQ-P1-021 | Algorithm 1 lines 2-5 | Failed candidate handling | -- |
| REQ-P1-022 | Algorithm 1 | All candidates failed | -- |
| REQ-P1-023 | Algorithm 1 line 6 | Sort by score (permutation pi) | -- |
| REQ-P1-024 | Algorithm 1 lines 6-7 | Initialize s_0 and h_best | -- |
| REQ-P1-025 | Algorithm 1 lines 8-17 | Merge loop | -- |
| REQ-P1-026 | Algorithm 1 line 11 | `>=` comparison semantics | `is_improvement_or_equal()` |
| REQ-P1-027 | Algorithm 1 lines 14-16 | Break-on-first-failure | -- |
| REQ-P1-028 | Algorithm 1 lines 8-17 | Merge execution failure as failed merge | -- |
| REQ-P1-029 | Algorithm 1 lines 8-17 | Single candidate, no merge | -- |
| REQ-P1-030 | Section 3.4 | `s_0 <- A_data(s_0, T_task)` | -- |
| REQ-P1-031 | Section 3.4 | Leakage check after A_data | -- |
| REQ-P1-032 | Algorithm 1 | Phase1Result construction | -- |
| REQ-P1-033 | Algorithm 1 | Score consistency | -- |
| REQ-P1-034 | Algorithm 1 lines 2-5 | Candidate independence | -- |
| REQ-P1-035 | Algorithm 1 line 4 | Evaluation independence | -- |
| REQ-P1-036 | Algorithm 1 lines 8-17 | Merge loop sequential | -- |
| REQ-P1-037 | -- | Orchestration overhead | -- |
| REQ-P1-038 | -- | Logging | Python `logging` |
| REQ-P1-039 | -- | SDK-only invocation | `claude-agent-sdk` |
| REQ-P1-040 | -- | Module organization | -- |
| REQ-P1-041 | Appendix B | Algorithm 1 fidelity | -- |
| REQ-P1-042 | Section 3.4 | Leakage integration points | -- |
| REQ-P1-043 | Figure 9 | Retriever prompt fidelity | -- |
| REQ-P1-044 | Figure 10 | Init prompt fidelity | -- |
| REQ-P1-045 | Figure 11 | Merger prompt fidelity | -- |

### 10.2 Cross-References to Other Specs

| Req ID | Referenced By |
|--------|--------------|
| REQ-P1-018 (run_phase1) | Spec 09 (Orchestrator invokes Phase 1) |
| REQ-P1-032 (Phase1Result) | Spec 05 (Phase 2 takes Phase1Result.initial_solution as input) |
| REQ-P1-032 (Phase1Result) | Spec 09 (Orchestrator stores Phase1Result in FinalResult) |

### 10.3 Spec 01 Dependencies (Inbound)

| Spec 01 Req ID | Used By (this spec) | Purpose |
|----------------|---------------------|---------|
| REQ-DM-001 (PipelineConfig) | REQ-P1-002, REQ-P1-007, REQ-P1-012, REQ-P1-017, REQ-P1-018 | M parameter, config for evaluation |
| REQ-DM-007 (TaskDescription) | REQ-P1-002, REQ-P1-007, REQ-P1-009, REQ-P1-012, REQ-P1-018, REQ-P1-030 | Task description for prompts and evaluation |
| REQ-DM-009 (SolutionScript) | REQ-P1-010, REQ-P1-012, REQ-P1-015, REQ-P1-017, REQ-P1-020 | Solution wrapper for candidate and merged scripts |
| REQ-DM-013 (AgentType) | REQ-P1-001, REQ-P1-008, REQ-P1-013 | Agent identity enum values |
| REQ-DM-014 (RetrievedModel) | REQ-P1-004, REQ-P1-006, REQ-P1-007, REQ-P1-012 | Model schema for retriever output |
| REQ-DM-015 (RetrieverOutput) | REQ-P1-003, REQ-P1-004, REQ-P1-005 | Structured output schema for retriever |
| REQ-DM-022 (Phase1Result) | REQ-P1-018, REQ-P1-032, REQ-P1-033 | Return type of run_phase1 |
| REQ-DM-029 (is_improvement_or_equal) | REQ-P1-025, REQ-P1-026 | Score comparison in merge loop |
| REQ-DM-032 (PromptRegistry) | REQ-P1-002, REQ-P1-007, REQ-P1-009, REQ-P1-012, REQ-P1-014, REQ-P1-017 | Template retrieval for all agents |
| REQ-DM-036 (AgentConfig) | REQ-P1-001, REQ-P1-008, REQ-P1-013 | Agent-to-SDK mapping |

### 10.4 Spec 02 Dependencies (Inbound)

| Spec 02 Req ID | Used By (this spec) | Purpose |
|----------------|---------------------|---------|
| REQ-EX-015 (evaluate_solution) | REQ-P1-020, REQ-P1-025, REQ-P1-030, REQ-P1-031 | Evaluate candidate and merged solutions |
| REQ-EX-021 (evaluate_with_retry) | REQ-P1-020, REQ-P1-025, REQ-P1-030, REQ-P1-031 | Evaluate with debug retry support |
| REQ-EX-026 (evaluate_batch) | REQ-P1-035 | Batch evaluation of candidates |
| REQ-EX-027 (rank_solutions) | REQ-P1-023 | Sort candidates by score |

### 10.5 Spec 03 Dependencies (Inbound)

| Spec 03 Req ID | Used By (this spec) | Purpose |
|----------------|---------------------|---------|
| REQ-SF-005 (extract_code_block) | REQ-P1-011, REQ-P1-016 | Code extraction from A_init and A_merger responses |
| REQ-SF-007 (make_debug_callback) | REQ-P1-020, REQ-P1-025 | Debug callback for evaluate_with_retry |
| REQ-SF-020 (check_and_fix_leakage) | REQ-P1-020, REQ-P1-025, REQ-P1-031, REQ-P1-042 | Leakage detection and correction before evaluation |
| REQ-SF-022 (leakage integration point) | REQ-P1-042 | Leakage check requirement on every solution |
| REQ-SF-030 (check_data_usage) | REQ-P1-030 | Data usage check after merging |

---

## 11. Change Control

### 11.1 Version History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 0.1.0 | 2026-02-20 | MLE-STAR Team | Initial draft -- all 45 requirements |

### 11.2 Baselining Policy

This SRS is baselined at version 1.0. After baselining, changes require impact analysis against Specs 05 and 09 (downstream consumers of Phase1Result), Spec 01 (upstream data model dependencies), Spec 02 (upstream execution harness dependencies), and Spec 03 (upstream safety agent dependencies).
